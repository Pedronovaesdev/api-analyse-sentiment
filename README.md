# ‚ö° API An√°lise de Sentimento (Squad-06)

Uma API intermedi√°ria constru√≠da com FastAPI para receber textos, encaminhar para um servi√ßo de infer√™ncia BERT externo (outra API), processar e enriquecer as respostas (normaliza√ß√£o, regras de neg√≥cio, logging e persist√™ncia opcional) e expor resultados de an√°lise de sentimento prontos para consumo por clientes front-end ou pipelines.

Resumo r√°pido:
- Recebe dados textuais via endpoint HTTP.
- Empacota e publica mensagens para uma fila RabbitMQ (mensageria resiliente).
- Um worker/consumer consome da fila, chama a API BERT externa (inference), processa resultados e persiste/retorna os resultados via callback ou armazenamento.
- Agrega e transforma a resposta do modelo (score, r√≥tulo, metadata).
- Opcionalmente persiste resultados, apresenta m√©tricas e exp√µe endpoints de sa√∫de/status.

---

## üîé Vis√£o geral do fluxo de dados

1. Cliente envia payload (texto) para esta API.
2. API valida e prepara a requisi√ß√£o.
3. API publica uma mensagem na fila RabbitMQ (publisher) contendo o input + metadata.
4. Um ou mais workers consomem mensagens da fila, chamam a API BERT externa (BERT_INFERENCE), recebem a resposta e aplicam regras de normaliza√ß√£o/thresholds.
5. Worker persiste resultado (DB) e/ou publica resultado em outra fila / endpoint de callback (webhook) para que o cliente ou outro servi√ßo recupere o resultado.
6. API retorna confirma√ß√£o imediata ao cliente (aceite/queued) e o resultado final √© obtido ap√≥s processamento ass√≠ncrono.

Observa√ß√£o: o uso de RabbitMQ melhora resili√™ncia, desacoplamento e escalabilidade para alto volume de requisi√ß√µes.

---

## üì¶ Funcionalidades principais

- Endpoint de an√°lise de sentimento (single / batch) ‚Äî aceita e enfileira.
- Arquitetura ass√≠ncrona com RabbitMQ (publisher + consumer).
- L√≥gica de retry, DLQ (dead-letter queue) e hist√≥rico de falhas.
- Encaminhamento seguro para API BERT (com timeouts, retries e headers) feito pelos workers consumers.
- Pydantic models para valida√ß√£o de payloads.
- Respostas padronizadas com confid√™ncias e r√≥tulos.
- Health-check, metrics (basic) e monitoramento do estado da fila.
- Configura√ß√£o via .env (facilita integra√ß√£o com CI/CD).
- Testes unit√°rios com pytest (skeleton).

---

## üìò Arquitetura de Mensageria ‚Äî RabbitMQ (detalhes importantes)

- Papel: desacoplar recep√ß√£o de requisi√ß√µes (API) do processamento de infer√™ncia (worker). A API atua como publisher; worker(s) consomem, chamam BERT externo e persistem/retornam resultados.
- Exchanges & Queues recomendadas:
  - exchange: sentiment.inference (type: direct/topic)
  - queue: sentiment.requests (durable)
  - queue de resposta/callback: sentiment.results (durable) ou usar webhook/DB
  - dead-letter-exchange: sentiment.dlx ‚Üí dead-letter queue: sentiment.failed
- Mensagens:
  - Formato JSON, id √∫nico (uuid), timestamp, payload.text, metadata, reply_to/callback_url opcional.
  - Exemplo:
    {
      "id": "uuid-v4",
      "text": "Amei o servi√ßo!",
      "metadata": {"source":"app","user_id":"u123"},
      "enqueue_at": "2025-11-30T12:00:00Z",
      "reply_to": "http://client/callback" // opcional
    }
- Garantias / melhores pr√°ticas:
  - Filas dur√°veis + mensagens persistent.
  - Acknowledgements expl√≠citos (ack / nack).
  - Prefetch (QoS) configurado no consumer para controlar concorr√™ncia (ex.: prefetch_count=10).
  - Dead-lettering para mensagens mal-formatadas ou falhas repetidas.
  - Retry exponencial no worker (retries controlados) antes de enviar para DLQ.
  - Idempot√™ncia no processamento (track processed ids) para evitar reprocessamento.
  - Monitora√ß√£o (RabbitMQ Management UI) e m√©tricas exportadas (Prometheus).
- Escalabilidade:
  - Escalar consumers horizontalmente para aumentar throughput.
  - Separar filas por prioridade ou payload size.
  - Use conex√£o / channel pooling para performance.

---

## üõ† Tech stack

- Python 3.10+
- FastAPI
- Uvicorn
- httpx (cliente HTTP ass√≠ncrono)
- Pydantic
- aio-pika / pika / kombu (client RabbitMQ, ass√≠ncrono recomendado)
- pytest (testes)
- Optional: Redis/Cache, PostgreSQL/SQLite

---

## ‚öôÔ∏è Vari√°veis de ambiente (exemplo .env)

Crie `.env` a partir de `.env.example` e configure:

- BERT_API_URL=https://bert-inference.example.com/predict
- BERT_API_KEY=seu_token (se necess√°rio)
- BERT_TIMEOUT=10
- RABBITMQ_URL=amqp://user:password@localhost:5672/
- RABBITMQ_EXCHANGE=sentiment.inference
- RABBITMQ_REQUEST_QUEUE=sentiment.requests
- RABBITMQ_RESULT_QUEUE=sentiment.results
- RABBITMQ_DLX=sentiment.dlx
- RABBITMQ_PREFETCH=10
- RETRY_MAX_ATTEMPTS=5
- APP_HOST=0.0.0.0
- APP_PORT=8000
- LOG_LEVEL=info
- DATABASE_URL=sqlite:///./data/app.db (opcional)
- CACHE_URL=redis://localhost:6379/0 (opcional)

---

## üöÄ Como rodar local (Windows) ‚Äî com RabbitMQ

1. Clone
   ```
   git clone <repo-url>
   cd api-analyse-sentiment
   ```

2. Ambiente virtual e depend√™ncias
   ```
   python -m venv venv
   .\venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. Iniciar RabbitMQ (via Docker Compose recomendado)
   Exemplo docker-compose m√≠nimo:
   ```yaml
   version: "3.8"
   services:
     rabbitmq:
       image: rabbitmq:3-management
       ports:
         - "5672:5672"
         - "15672:15672"
       environment:
         RABBITMQ_DEFAULT_USER: user
         RABBITMQ_DEFAULT_PASS: password
   ```
   Acesse UI: http://localhost:15672 (user/password)

4. Preparar .env (copiar .env.example ‚Üí .env) e ajustar RABBITMQ_URL / BERT_API_URL.

5. Executar API (publisher)
   ```
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

6. Executar worker (consumer)
   - Script worker separado: ex.: worker.py que consome da fila e chama BERT_API.
   - Rodar worker(s) em background / container separado.

---

## üß≠ Endpoints principais

1) /health
- GET ‚Äî Retorna status da API e integra√ß√£o b√°sica com RabbitMQ (connection ok).

2) /api/v1/analyze
- POST ‚Äî Enfileira texto para processamento ass√≠ncrono.
Exemplo request:
```json
{
  "id": "abc123",
  "text": "Eu adorei o produto! Recomendaria para amigos.",
  "metadata": { "source": "web" },
  "callback_url": "http://cliente/callback" // opcional
}
```

Resposta imediata exemplo:
```json
{
  "id": "abc123",
  "status": "queued",
  "queued_at": "2025-11-30T12:34:56Z"
}
```

3) /api/v1/analyze/batch
- POST ‚Äî Recebe array de textos e enfileira em lote.

4) /api/v1/results/{id}
- GET ‚Äî (opcional) Recupera resultado final (se persistido no DB).

5) /metrics
- GET ‚Äî m√©tricas simples / contadores / health da fila.

---

## üí° Boas pr√°ticas implementadas

- Publisher confirma publica√ß√£o; consumers usam ack/nack.
- Retry exponencial e DLQ para falhas persistentes.
- Prefetch/limita√ß√£o para controlar mem√≥ria/throughput.
- Logging estruturado e trace_id para correlacionar mensagens.
- Testes com mocking de RabbitMQ (aio-pika / fixtures).
- Separar worker em um processo/container independente.

---

## üß™ Testes

Rodar testes:
```
pytest -q
```

Sugest√£o: adicionar testes para mocks de chamadas √† API BERT (httpx.MockTransport) e para comportamento de fila (ex.: RabbitMQ stub, aio-pika Testing).

---

## üì¶ Deploy / Produ√ß√£o

- Containerize com Docker (adicionar Dockerfile) e um servi√ßo worker separado.
- Orquestra√ß√£o: Kubernetes / Docker Compose com configura√ß√£o das filas, readiness/liveness probes e limita√ß√£o de recursos.
- Use filas dur√°veis e r√©plica de brokers (HA) se necess√°rio.
- Segredos para credenciais (Key Vault / Secrets Manager).
- Monitoramento: Prometheus node-exporter + RabbitMQ exporter + logs centralizados.

---

## üîß Observa√ß√µes importantes sobre BERT externo e RabbitMQ

- Esta API n√£o executa BERT localmente ‚Äî consumidores chamam a API BERT.
- Contrato: BERT externo deve retornar label/probabilities/embedding conforme schema esperado.
- Gateway de mensageria garante entrega confi√°vel; configure DLQ e idempot√™ncia.
- Ajuste thresholds e mapeamento de labels (POS/NEG/NEU) na camada de processamento do worker.

---

## ü§ù Como contribuir

1. Fa√ßa fork do reposit√≥rio.
2. Crie branch: feature/minha-melhoria
3. Adicione testes.
4. PR com descri√ß√£o clara.

---

## üìú Licen√ßa

Escolha a licen√ßa do projeto (ex.: MIT). Atualize o arquivo LICENSE no reposit√≥rio.

---

Se quiser, eu gero:
- template de Dockerfile + docker-compose com worker e broker;
- worker.py exemplo (consumer) com retry, DLQ e chamada ao BERT;
- testes unit√°rios exemplares para endpoints, mocks do BERT e integra√ß√£o com RabbitMQ.